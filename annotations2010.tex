\documentclass{elsart}

\usepackage{listings}

\begin{document}
% TODO:  need a title
\title{Super Awesome Title Goes Here}
\author[UMN]{Garrett Holmstrom}
\ead{garrett@cs.umn.edu}

\address[UMN]{Dept. of Computer Science and Engineering,
    University of Minnesota, 4-192 EE/CS Bldg., 200 Union St SE,
    Minneapolis, MN 55455, USA.}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

% TODO:  basic information about TAC-SCM?

\subsection{MinneTAC architecture}

Our TAC-SCM agent, MinneTAC, is a Java application designed to minimize
coupling between its components to support independent work on multiple
lines of research.  To that end we use a component-oriented approach...
% TODO:  finish above

A MinneTAC agent consists of a set of components for each major decision
process in the TAC-SCM game: \textsc{Procurement}, \textsc{Production},
\textsc{Sales}, and \textsc{Shipping}.  All data to be shared
among components are kept in the Repository, which plays the role
of the Blackboard in the \emph{Blackboard} pattern\cite{Busch96}.
The \textsc{Communications} component manages interaction with the game
server.  Finally, the \textsc{Oracle} component contains a large number
of smaller components that maintain models of markets and inventory and
perform analyses and predictions.  Ideally, each of these components
depends solely upon the \textsc{Repository}, which completely separates
major decision processes and allowing researchers to work on them
independently.

% TODO:  hub-and-spoke diagram

Since decision components cannot depend on one another, they communicate
using \emph{evaluations} that are accessible through the various data
elements in the \textsc{Repository}.  Any calculations or analyses that
are performed on \textsc{Repository} data can be encapsulated in the
form of evaluations and made available to all other components via the
\textsc{Repository}.  The \textsc{Oracle} component contains a large
number of configurable \emph{evaluator} classes that perform analyses
on \textsc{Repository} data.

All the major data elements in the \textsc{Repository}, such as RFQs,
offers, components, and so forth, are Evaluable types.  Each Evaluable can
be queried for related Evaluations by passing it the name of the needed
evaluation.  An EvaluationFactory maintains a mapping of Evaluation
names to Evaluator instances, and calls upon Evaluators to produce
Evaluations on demand.  Evaluators can back-chain by requesting other
Evaluations as they attempt to produce their results.  By this means,
an Evaluation may be composed from several other Evaluations that are
in turn generated by their own Evaluators.

The resulting \textsc{Oracle} component is essentially a framework for
a set of small, configurable sub-components from which other components
can request analyses and predictions.  Most of these sub-components
are Evaluators, though other types also exist.  The \textsc{Oracle}
itself merely uses its configuration data to create and configure
instances of Evaluators and other subclasses of ConfiguredObject.
\emph{ConfiguredObject} is an abstract class whose instances have names
and some ability to configure themselves, given an appropriate clause from
a XML configuration file.  The \textsc{Oracle} creates ConfiguredObject
instances and keeps track of them by mapping their names as given in
the configuration file to instances.

% TODO:  UML diagram?

During initialization, the \textsc{Oracle} processes a configuration
clause that specifies which instances to create, and for each such
instance, what name to give it, the values of any parameters necessary to
configure it, and the names of any instances it queries for input data.
Figure~\ref{lst:xconf-simpleprice} illustrates such a configuration
clause for an evaluator with one parameter and four inputs.

\begin{lstlisting}[language={XML},frame={single},belowcaptionskip=0.4cm,
label={lst:xconf-simpleprice},caption={Configuration clause for a price
evaluator that uses one parameter and several inputs}]
<evaluator class="edu.umn.cs.tac.oracle.eval.SimplePriceEvaluator"
    name="simple-price">
    <parameters price-probability-exponent="1.0"/>
</evaluator>
<graph source="simple-price">
    <quantity source="customer-quantity"/>
    <effective-demand source="effective-demand"/>
    <allocation source="allocation"/>
    <regression source="probability-of-acceptance"/>
</graph>
\end{lstlisting}

Taken together, a set of Evaluators and other ConfiguredObjects comprises
a directed graph of modular components that constitute the majority
of the functional code used in a MinneTAC agent workflow.  MinneTAC's
modular architecture allows one to easily substitute components for one
another for comparative purposes or to create an entirely new set of
components with only minimal knowledge of how the agent works internally.
Additionally, using configuration files to defnie graphs of components
allows developers to add new components without disrupting other
developers' configurations.

\subsection{Usability challenges}

MinneTAC Evaluators gather input data of specific types from zero or
more other Evaluators, then use these data to produce one output of a
given type.  In addition to having a specific set of inputs and outputs,
Evaluators frequently have configuration parameters that affect how they
behave.  Common parameters include exponents and probability thresholds.
Creating an agent workflow involves choosing a set of Sink components
from which the main decision-making components request data, choosing
appropriate graphs of Evaluators that generate the data the chosen Sinks
require, and finally configuring the individual Evaluators.

Historically, MinneTAC has proved itself difficult to configure because of
how complex agent workflows, which tend to have graphs of over one hundred
evaluators, tend to be.  This makes using the agent much less accessible
to users who are less familiar with every available Evaluator.  Adding a
component to a particular part of an agent workflow configuration requires
one to choose among hundreds of Evaluators, most of which have inputs
or outputs that are incompatible with the graph location in question.

Gil et al.~\cite{gil2010wings} identify a key issue that workflow
designers face: tracking and checking input and output data types becomes
onerous as the size of systems or the number of available components
increase.  We aim to simplify the configuration process by creating a
graphical editor for agent workflow configurations.  However, a graphical
editor alone does nothing to fix the problem arising from the sheer
number of Evaluators one has to choose from and thus be familiar with.
By taking context into account and only displaying Evaluators whose
input or output data types are compatible with the Evaluator selected
in the editor we require users to be familiar with only a small subset
of all Evaluators to be able to reasonably choose which Evaluator is
appropriate for a given location in the workflow.

Numerous frameworks and applications attempt to solve this problem with a variety of methods for specifying and processing the metadata needed to connect inputs with lists of compatible outputs.  An informal survey of some of them reveals several key approaches.



\end{document}
